{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import ccxt\n",
    "import os\n",
    "import time\n",
    "from config_parameters import MARKET_DATA_DICT\n",
    "folder_data= MARKET_DATA_DICT\n",
    "interval_mapping = {\n",
    "    '1M': {'name': '1M', 'dataOffset': pd.Timedelta(days=31)},\n",
    "    '2w': {'name': '1w', 'dataOffset': pd.Timedelta(days=14)},\n",
    "    '1w': {'name': '1w', 'dataOffset': pd.Timedelta(days=7)},\n",
    "    '3d': {'name': '3d', 'dataOffset': pd.Timedelta(days=3)},\n",
    "    '2d': {'name': '2d', 'dataOffset': pd.Timedelta(days=2)},\n",
    "    '1d': {'name': '1d', 'dataOffset': pd.Timedelta(days=1)},\n",
    "    '12h': {'name': '12h', 'dataOffset': pd.Timedelta(hours=12)},\n",
    "    '8h': {'name': '8h', 'dataOffset': pd.Timedelta(hours=8)},\n",
    "    '7h': {'name': '7h', 'dataOffset': pd.Timedelta(hours=7)},\n",
    "    '6h': {'name': '6h', 'dataOffset': pd.Timedelta(hours=6)},\n",
    "    '4h': {'name': '4h', 'dataOffset': pd.Timedelta(hours=4)},\n",
    "    '2h': {'name': '2h', 'dataOffset': pd.Timedelta(hours=2)},\n",
    "    '1h': {'name': '1h', 'dataOffset': pd.Timedelta(hours=1)},\n",
    "    '30m': {'name': '30m', 'dataOffset': pd.Timedelta(minutes=30)},\n",
    "    '15m': {'name': '15m', 'dataOffset': pd.Timedelta(minutes=15)},\n",
    "    '10m': {'name': '10m', 'dataOffset': pd.Timedelta(minutes=10)},\n",
    "    '5m': {'name': '5m', 'dataOffset': pd.Timedelta(minutes=5)},\n",
    "    '3m': {'name': '3m', 'dataOffset': pd.Timedelta(minutes=3)},\n",
    "    '1m': {'name': '1m', 'dataOffset': pd.Timedelta(minutes=1)},\n",
    "}\n",
    "\n",
    "def download_newest_data(symbol, timeframe, since='2000-01-01 00:00:00', end='2030-02-01 00:00:00', batch=3, dataOffset=pd.Timedelta(days=1)):\n",
    "    # Ensure since and end are pd.Timestamp objects\n",
    "    since = pd.to_datetime(since)\n",
    "    end = pd.to_datetime(end)\n",
    "    \n",
    "    # Utwórz obiekt dostawcy danych\n",
    "    exchange = ccxt.binance()\n",
    "    next_since = None\n",
    "    # Utwórz pusty DataFrame do przechowywania danych\n",
    "    data_frames = []\n",
    "    trials=0\n",
    "    # Utwórz pętlę do wczytywania danych partiami\n",
    "    while True:\n",
    "        try:\n",
    "        # Pobierz dane OHLCV\n",
    "            if next_since:\n",
    "                since = next_since\n",
    "            since = exchange.parse8601(since.isoformat())\n",
    "            data = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=batch)\n",
    "            df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            data_frames.append(df)\n",
    "            trrials=0\n",
    "            # Sprawdź, czy są jeszcze dane\n",
    "            if len(data) == batch:\n",
    "                next_since = df.iloc[-1]['timestamp'] + dataOffset\n",
    "                if 'M' in timeframe:\n",
    "                    next_since = next_since.replace(day=1)\n",
    "                # Ustaw dzień na 1, aby uzyskać pierwszy dzień następnego miesiąca\n",
    "                next_since = pd.to_datetime(next_since, unit='ms')\n",
    "                if next_since >= end:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        except exchange.exceptions.RequestException as e:\n",
    "            print(f\"⚠️ Błąd podczas pobierania danych: {e}\")\n",
    "            if trials<3:\n",
    "                print(\"⏳ Czekam 2 sekundy przed ponowną próbą...\")\n",
    "                trials+=1\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"❌ Nie udało się pobrać danych po kilku próbach.\")\n",
    "                return None\n",
    "        except ccxt.NetworkError as e:\n",
    "            print(\"Błąd sieci:\", e)\n",
    "        except ccxt.BaseError as e:\n",
    "            print(\"Inny błąd CCXT:\", e)\n",
    "    # Połącz wszystkie ramki danych w jedną\n",
    "    if data_frames:\n",
    "        result_df = pd.concat(data_frames, ignore_index=True)\n",
    "        result_df = result_df[result_df['timestamp'] < end]  # Zapisz dane mniejsze od daty end, ale nie równe\n",
    "        return result_df\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def upload_data( folder,ticker, interval, start_date, end_date, add_indicators=False):\n",
    "\n",
    "    symbol=ticker.replace('/', '.')\n",
    "    # Utwórz ścieżkę do pliku\n",
    "    symbol_directory=os.path.join(folder, symbol)\n",
    "    if not os.path.exists(symbol_directory):\n",
    "    # Jeśli nie istnieje, utwórz go\n",
    "        os.makedirs(symbol_directory)\n",
    "    file_path = os.path.join(symbol_directory, interval+'.csv')\n",
    "    \n",
    "    combined_data = download_newest_data(ticker, interval, start_date, end_date, batch=1000, dataOffset =interval_mapping[interval]['dataOffset'])\n",
    "    combined_data.to_csv(file_path, index=False)\n",
    "    return combined_data\n",
    "    \n",
    "def save_resampled_data(folder, df, ticker, interval):\n",
    "    \n",
    "    symbol=ticker.replace('/', '.')\n",
    "    symbol_directory=os.path.join(folder, symbol)\n",
    "    file_path = os.path.join(symbol_directory, interval+'.csv')\n",
    "    df.to_csv(file_path, index=False)\n",
    "    return df\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(ticker, interval, folder):\n",
    "    # Replace '/' with '.' in the ticker symbol\n",
    "    symbol = ticker.replace('/', '.')\n",
    "    \n",
    "    # Create the directory path\n",
    "    symbol_directory = os.path.join(folder, symbol)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(symbol_directory):\n",
    "        os.makedirs(symbol_directory)\n",
    "    \n",
    "    # Create the file path\n",
    "    file_path = os.path.join(symbol_directory, interval + '.csv')\n",
    "    \n",
    "    # Load the data from the CSV file if it exists\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "# Assuming you have a folder named 'data' and you want to load data for 'BTC/USD' with '1h' interval\n",
    "\n",
    "\n",
    "\n",
    "def resample_data(df, interval):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Ustawienie kolumny 'timestamp' jako indeks\n",
    "\n",
    "    new_df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    if interval.endswith('m'):\n",
    "        interval = interval[:-1] + 't'\n",
    "    new_df.set_index('timestamp', inplace=True)\n",
    "    resampled_df = new_df.resample(interval).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    }).dropna()\n",
    "    resampled_df.reset_index(inplace=True)\n",
    "    return resampled_df\n",
    "\n",
    "\n",
    "def load_row_data_and_save(folder, symbol, intervals, start_date, end_date):\n",
    "    basic_data = upload_data(folder,symbol,intervals[-1], start_date, end_date, False)\n",
    "    save_resampled_data(folder, basic_data, symbol, intervals[-1])\n",
    "    return basic_data\n",
    "\n",
    "\n",
    "def resame_data_and_save(basic_data,folder, symbol, intervals):   \n",
    "        for interval in intervals:\n",
    "            data_resampled=resample_data(basic_data,interval)\n",
    "            save_resampled_data(folder,data_resampled, symbol, interval)\n",
    "\n",
    "\n",
    "def save_row_data_1m_1d(ticker):\n",
    "    basic_data=load_row_data_and_save(folder_data, ticker, ['1m'], '2006-01-01 00:00:00', '2025-03-01 00:00:00')\n",
    "    resame_data_and_save(basic_data,folder_data, ticker, ['5m', '15m', '30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n",
    "\n",
    "def save_row_data_5m_1d(ticker):\n",
    "    basic_data=load_row_data_and_save(folder_data, ticker, ['5m'], '2006-01-01 00:00:00', '2025-03-01 00:00:00')\n",
    "    resame_data_and_save(basic_data,folder_data, ticker, [ '15m', '30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n",
    "def save_row_data_15m_1d(ticker):\n",
    "    basic_data=load_row_data_and_save(folder_data, ticker, ['15m'], '2006-01-01 00:00:00', '2025-03-01 00:00:00')\n",
    "    resame_data_and_save(basic_data,folder_data, ticker, [ '30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_daily_to_weekly(df, interval, reference_date=None):\n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Set the index to timestamp\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    first_entry = df.iloc[0]\n",
    "    closest_diff=-1\n",
    "    # Resample data to weekly, starting from Monday, November 11, 2024\n",
    "    if interval=='1w':\n",
    "        \n",
    "        df_resampled = df.resample('W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    elif interval == '2w':\n",
    "        df_resampled = df.resample('2W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=12)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=12))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('2W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "\n",
    "\n",
    "    elif interval == '1M':\n",
    "        df_resampled = df.resample('MS', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "        \n",
    "    elif interval == '2M':\n",
    "        df_resampled = df[df.index.month % 2 == 0].resample('MS').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif interval == '2d':\n",
    "\n",
    "        df_resampled = df.resample('2D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=1)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=1))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('2D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "    \n",
    "\n",
    "\n",
    "    elif interval == '3d':\n",
    "        df_resampled = df.resample('3D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=2)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=2))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(0, closest_diff):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('3D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "    elif interval == '3M':\n",
    "        df_resampled = df.resample('QS', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=60)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=60))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('Q', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "        \n",
    "            print(df_resampled)\n",
    "\n",
    "    \n",
    "    # Reset index to get timestamp as a column\n",
    "    df_resampled.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_resampled\n",
    "\n",
    "# Load your data (Assuming CSV format, adjust if JSON)\n",
    "\n",
    "\n",
    "def resample_data_and_save(folder, symbol, interval, reference_data):\n",
    "    basic_data = load_data(symbol, '1d', folder)\n",
    "    resampled_data = resample_daily_to_weekly(basic_data, interval, reference_date=reference_data)\n",
    "\n",
    "    save_resampled_data(folder, resampled_data, symbol, interval)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_binance_data(tickers, min_interval=\"5m\"):\n",
    "    folder = MARKET_DATA_DICT\n",
    "\n",
    "    for ticker in tickers:\n",
    "        # Download raw data depending on min_interval\n",
    "        if min_interval == \"1m\":\n",
    "            save_row_data_1m_1d(ticker)\n",
    "        elif min_interval == \"5m\":\n",
    "            save_row_data_5m_1d(ticker)\n",
    "        elif min_interval == \"15m\":\n",
    "            save_row_data_15m_1d(ticker)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported min_interval: {min_interval}. Supported: '1m', '5m', '15m'\")\n",
    "        resample_data_and_save(folder, ticker, \"2d\", reference_data=pd.Timestamp(\"2025-01-31\"))\n",
    "        resample_data_and_save(folder, ticker, \"3d\", reference_data=pd.Timestamp(\"2025-01-31\"))\n",
    "        resample_data_and_save(folder, ticker, \"1w\", reference_data=pd.Timestamp(\"2024-12-30\"))\n",
    "        resample_data_and_save(folder, ticker, \"2w\", reference_data=pd.Timestamp(\"2024-12-30\"))\n",
    "        resample_data_and_save(folder, ticker, \"1M\", reference_data=pd.Timestamp(\"2024-12-01\"))\n",
    "        resample_data_and_save(folder, ticker, \"3M\", reference_data=pd.Timestamp(\"2024-10-01\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arek\\AppData\\Local\\Temp\\ipykernel_52448\\1774088950.py:150: FutureWarning: 't' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = new_df.resample(interval).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arek\\AppData\\Local\\Temp\\ipykernel_52448\\1774088950.py:150: FutureWarning: 't' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = new_df.resample(interval).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp      open      high       low     close      volume\n",
      "0      2017-08-17 04:00:00   4261.48   4280.56   4261.48   4261.48    2.189061\n",
      "1      2017-08-17 04:05:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "2      2017-08-17 04:10:00   4261.48   4261.48   4261.48   4261.48    0.000000\n",
      "3      2017-08-17 04:15:00   4261.48   4264.88   4261.48   4261.48    0.484666\n",
      "4      2017-08-17 04:20:00   4264.88   4266.29   4264.88   4266.29    2.328570\n",
      "...                    ...       ...       ...       ...       ...         ...\n",
      "791096 2025-02-28 23:35:00  84185.18  84245.29  84132.07  84245.28   29.817790\n",
      "791097 2025-02-28 23:40:00  84245.29  84431.05  84245.28  84400.01   57.610650\n",
      "791098 2025-02-28 23:45:00  84400.01  84537.03  84343.82  84505.36  189.068650\n",
      "791099 2025-02-28 23:50:00  84505.35  84548.43  84422.00  84488.62   40.668150\n",
      "791100 2025-02-28 23:55:00  84488.61  84488.62  84349.94  84349.94   27.107680\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arek\\AppData\\Local\\Temp\\ipykernel_52448\\1774088950.py:150: FutureWarning: 't' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = new_df.resample(interval).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arek\\AppData\\Local\\Temp\\ipykernel_52448\\1774088950.py:150: FutureWarning: 't' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  resampled_df = new_df.resample(interval).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n",
      "                 timestamp     open     high      low    close      volume\n",
      "0      2017-08-17 04:00:00   301.13   301.13   300.00   301.13     3.82951\n",
      "1      2017-08-17 04:05:00   300.00   301.13   298.00   298.00     1.97216\n",
      "2      2017-08-17 04:10:00   298.00   298.00   298.00   298.00     0.00000\n",
      "3      2017-08-17 04:15:00   298.00   299.05   298.00   299.05    12.88486\n",
      "4      2017-08-17 04:20:00   299.05   300.10   299.05   300.10     6.58304\n",
      "...                    ...      ...      ...      ...      ...         ...\n",
      "791096 2025-02-28 23:35:00  2228.39  2235.31  2227.70  2235.13  1128.63000\n",
      "791097 2025-02-28 23:40:00  2235.13  2236.54  2231.50  2236.37   898.32720\n",
      "791098 2025-02-28 23:45:00  2236.37  2238.31  2232.30  2235.41  1279.50460\n",
      "791099 2025-02-28 23:50:00  2235.41  2238.87  2234.93  2236.00   519.17260\n",
      "791100 2025-02-28 23:55:00  2236.00  2239.69  2235.16  2237.59   540.44470\n",
      "\n",
      "[791101 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "tickers=['BTCUSDT', 'ETHUSDT', 'DOGEUSDT', 'LINKUSDT', 'SUIUSDT', 'ZROUSDT', 'ADAUSDT', 'TRXUSDT', 'WLDUSDT' , 'PEPEUSDT', 'DYMUSDT']\n",
    "tickers=['BTCUSDT', 'ETHUSDT']\n",
    "download_binance_data(tickers, \"5m\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BOT-TRADING",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
