{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def get_stock_exchanges(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/exchanges\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"type\": \"stocks\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "def save_data_to_file(data, folder=\"Profit2.com\", filename=\"stocks.json\"):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filepath}\")\n",
    "\n",
    "\n",
    "def load_data_from_file(folder=\"Profit2.com\", filename=\"stocks.json\"):\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    \n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File {filepath} does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    with open(filepath, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    print(f\"Data loaded from {filepath}\")\n",
    "    return data\n",
    "\n",
    "\n",
    "# Podaj swój klucz API\n",
    "your_api_key = \"979b87d860da4871b9a3166ad55b1421\"\n",
    "#data = get_stock_exchanges(your_api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def get_stock_exchanges(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/exchanges\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"type\": \"stocks\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "def save_data_to_file(data, folder=\"Profit2.com\", filename=\"stocks.json\"):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filepath}\")\n",
    "\n",
    "# Podaj swój klucz API\n",
    "# data = get_stock_exchanges(your_api_key)\n",
    "\n",
    "# if data:\n",
    "#     print(data)\n",
    "#     save_data_to_file(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_stock_exchanges(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/exchanges\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"type\": \"stocks\",\n",
    "        \"code\": \"US\",\n",
    "        \"name\": \"USA Stocks\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_indices_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/indices\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"exchange\": \"F\",\n",
    "        \"available_data\": \"historical\",\n",
    "        \"type\": \"INDEX\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_stock_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/stocks\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        #\"symbol\": \"TSLA\",\n",
    "        \"exchange\": \"NASDAQ\",\n",
    "        \"country\": \"United States\",\n",
    "        \"currency\": \"USD\",\n",
    "        \"available_data\": \"historical\",\n",
    "        \"type\": \"Common Stock\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def save_data_to_file(data, folder=\"Profit.com\", filename=\"stocks.json\"):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filepath}\")\n",
    "\n",
    "\n",
    "# Podaj swój klucz API\n",
    "#data_stocks = get_stock_exchanges(your_api_key)\n",
    "\n",
    "# data_indices = get_indices_data(your_api_key)\n",
    "\n",
    "# #data_tsla = get_stock_data(your_api_key)\n",
    "\n",
    "# #if data_stocks:\n",
    "# #    save_data_to_file(data_stocks, filename=\"stocks.json\")\n",
    "\n",
    "# if data_indices:\n",
    "#     save_data_to_file(data_indices, filename=\"indices_new.json\")\n",
    "\n",
    "# if data_tsla:\n",
    "#     save_data_to_file(data_tsla, filename=\"nasdaq_stocks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forex_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/forex\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"group\": \"MAJOR\",\n",
    "        #\"currency_base\": \"EUR\",\n",
    "       # \"currency_quote\": \"USD\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"available_data\": \"historical\" #, fundamential\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "# data_forex = get_forex_data(your_api_key)\n",
    "\n",
    "# if data_forex:\n",
    "#     save_data_to_file(data_forex, filename=\"forex.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forex_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/forex\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        #\"group\": \"MAJOR\",\n",
    "        #\"currency_base\": \"EUR\",\n",
    "       # \"currency_quote\": \"USD\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"available_data\": \"historical\" #, fundamential\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "# data_forex = get_forex_data(your_api_key)\n",
    "\n",
    "# if data_forex:\n",
    "#     save_data_to_file(data_forex, filename=\"forex_all.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/crypto\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "       # \"algorithm\": \"SHA-256\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"symbol\": \"OM\",\n",
    "        \"available_data\": \"historical\",\n",
    "       # \"exchange\": \"CC\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "# data_crypto = get_crypto_data(your_api_key)\n",
    "# if data_crypto:\n",
    "#     save_data_to_file(data_crypto, filename=\"crypto_om.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commodity, Bonds\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_stock_exchanges(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/exchanges\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"type\": \"stocks\",\n",
    "        \"code\": \"US\",\n",
    "        \"name\": \"USA Stocks\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_indices_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/indices\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"symbol\": \"DJI\",\n",
    "        \"exchange\": \"INDX\",\n",
    "        \"country\": \"United States\",\n",
    "        \"currency\": \"USD\",\n",
    "        \"available_data\": \"historical,fundamental\",\n",
    "        \"type\": \"INDEX\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_stock_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/stocks\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"symbol\": \"TSLA\",\n",
    "        \"exchange\": \"NASDAQ\",\n",
    "        \"country\": \"United States\",\n",
    "        \"currency\": \"USD\",\n",
    "        \"available_data\": \"historical,fundamental\",\n",
    "        \"type\": \"Common Stock\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_forex_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/forex\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"group\": \"MAJOR\",\n",
    "        \"currency_base\": \"EUR\",\n",
    "        \"currency_quote\": \"USD\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"symbol\": \"EURUSD\",\n",
    "        \"available_data\": \"historical,fundamental\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_crypto_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/crypto\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"algorithm\": \"SHA-256\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"symbol\": \"BTC\",\n",
    "        \"available_data\": \"historical,fundamental\",\n",
    "        \"exchange\": \"CC\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_commodity_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/commodity\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "       # \"group\": \"ENERGY\",\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        \"available_data\": \"historical\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def get_bonds_data(api_key):\n",
    "    url = \"https://api.profit.com/data-api/reference/bonds\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"skip\": 0,\n",
    "        \"limit\": 1000,\n",
    "        #\"symbol\": \"US10Y\",\n",
    "        \"available_data\": \"historical\",\n",
    "        \"country\": \"United States\",\n",
    "        \"currency\": \"USD\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "def save_data_to_file(data, folder=\"Profit.com\", filename=\"stocks.json\"):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "    print(f\"Data saved to {filepath}\")\n",
    "\n",
    "# Podaj swój klucz API\n",
    "# your_api_key = \"your_api_key_here\"\n",
    "# data_stocks = get_stock_exchanges(your_api_key)\n",
    "\n",
    "# data_indices = get_indices_data(your_api_key)\n",
    "\n",
    "# data_tsla = get_stock_data(your_api_key)\n",
    "\n",
    "# data_forex = get_forex_data(your_api_key)\n",
    "\n",
    "# data_crypto = get_crypto_data(your_api_key)\n",
    "\n",
    "# data_commodity = get_commodity_data(your_api_key)\n",
    "\n",
    "# data_bonds = get_bonds_data(your_api_key)\n",
    "\n",
    "# if data_stocks:\n",
    "#     save_data_to_file(data_stocks, filename=\"stocks.json\")\n",
    "\n",
    "# if data_indices:\n",
    "#     save_data_to_file(data_indices, filename=\"indices.json\")\n",
    "\n",
    "# if data_tsla:\n",
    "#     save_data_to_file(data_tsla, filename=\"tsla.json\")\n",
    "\n",
    "# if data_forex:\n",
    "#     save_data_to_file(data_forex, filename=\"forex.json\")\n",
    "\n",
    "# if data_crypto:\n",
    "#     save_data_to_file(data_crypto, filename=\"crypto.json\")\n",
    "\n",
    "# if data_commodity:\n",
    "#     save_data_to_file(data_commodity, filename=\"commodity.json\")\n",
    "\n",
    "# if data_bonds:\n",
    "#     save_data_to_file(data_bonds, filename=\"bonds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytywane danych dniowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_stock_data(api_key, ticker):\n",
    "    url = f\"https://api.profit.com/data-api/market-data/historical/daily/{ticker}\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"ticker\":ticker,\n",
    "        \"start_date\": \"1990-01-01\",\n",
    "        \"end_date\": \"2025-02-10\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wczytywanie danych intraday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intraday_stock_data(api_key, ticker):\n",
    "    url = f\"https://api.profit.com/data-api/market-data/historical/intraday/{ticker}\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"start_time\": 1736467200,  # Timestamp for 2025-01-10\n",
    "        \"end_time\": 1738281600,    # Timestamp for 2025-01-31\n",
    "        \"interval\": \"1m\",\n",
    "        \"limit\": 500\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "# ticker=\"GSPC.INDX\"\n",
    "# ticker=\"DE30.COMM\"\n",
    "# ticker=\"NDX.INDX\"\n",
    "# ticker=\"DJI.INDX\"\n",
    "# data_historical_tsla = get_intraday_stock_data(your_api_key, ticker)\n",
    "\n",
    "# print(data_historical_tsla)\n",
    "# if data_historical_tsla:\n",
    "#     save_data_to_file(data_historical_tsla, filename=f\"{ticker}_intervals.json\")\n",
    "#     print(len(data_historical_tsla))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_intraday_stock_data_batch(api_key, ticker, interval, end_time=1738368000, batches=2, batch_size=500):\n",
    "    \"\"\"\n",
    "    Pobiera dane giełdowe w interwałach 1-minutowych, zaczynając od podanej daty końcowej\n",
    "    i cofając się wstecz w partiach po batch_size.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.profit.com/data-api/market-data/historical/intraday/{ticker}\"\n",
    "    \n",
    "    all_data = []\n",
    "    i=0\n",
    "    while i<batches:\n",
    "        params = {\n",
    "            \"token\": api_key,\n",
    "            \"end_time\": end_time,  # Timestamp dla końcowego czasu\n",
    "            \"interval\": interval,\n",
    "            \"limit\": batch_size\n",
    "        }\n",
    "        response = requests.get(url, params=params, stream=True)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if not data:\n",
    "                break  # Przerywamy, jeśli brak danych\n",
    "            \n",
    "            all_data = data + all_data\n",
    "\n",
    "            \n",
    "            # Ustawienie nowego end_time na najstarszy timestamp pobranych danych\n",
    "            end_time = min(item['t'] for item in data)\n",
    "            \n",
    "            # Opóźnienie, aby uniknąć zbyt częstych zapytań do API\n",
    "           # time.sleep(1)\n",
    "        else:\n",
    "            print(f\"Błąd: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "        i+=1\n",
    "    # Konwersja do DataFrame\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        df['timestamp'] = pd.to_datetime(df['t'], unit='s')\n",
    "        df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 'v': 'volume'}, inplace=True)\n",
    "        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_resampled_data(folder, df, ticker, interval):\n",
    "    \n",
    "    symbol=ticker.replace('/', '.')\n",
    "    # Utwórz ścieżkę do pliku\n",
    "    symbol_directory=os.path.join(folder, symbol)\n",
    "    if not os.path.exists(symbol_directory):\n",
    "    # Jeśli nie istnieje, utwórz go\n",
    "        os.makedirs(symbol_directory)\n",
    "    file_path = os.path.join(symbol_directory, interval+'.csv')\n",
    "\n",
    "    \n",
    "    df.to_csv(file_path, index=False)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(df, interval):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Ustawienie kolumny 'timestamp' jako indeks\n",
    "\n",
    "    new_df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    if interval.endswith('m'):\n",
    "        interval = interval[:-1] + 't'\n",
    "    new_df.set_index('timestamp', inplace=True)\n",
    "    resampled_df = new_df.resample(interval).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    }).dropna()\n",
    "    resampled_df.reset_index(inplace=True)\n",
    "    return resampled_df\n",
    "\n",
    "\n",
    "def resame_data_and_save(basic_data,folder, symbol, intervals):   \n",
    "        for interval in intervals:\n",
    "            data_resampled=resample_data(basic_data,interval)\n",
    "            save_resampled_data(folder,data_resampled, symbol, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_daily_to_weekly(df, interval, reference_date=None):\n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Set the index to timestamp\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    first_entry = df.iloc[0]\n",
    "\n",
    "    # Resample data to weekly, starting from Monday, November 11, 2024\n",
    "    if interval=='1w':\n",
    "        \n",
    "        df_resampled = df.resample('W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "    elif interval == '2w':\n",
    "        df_resampled = df.resample('2W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=12)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=12))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('2W-MON', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "\n",
    "\n",
    "    elif interval == '1M':\n",
    "        df_resampled = df.resample('MS', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "        \n",
    "    elif interval == '2M':\n",
    "        df_resampled = df[df.index.month % 2 == 0].resample('MS').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    elif interval == '2d':\n",
    "\n",
    "        df_resampled = df.resample('2D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=1)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=1))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('2D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "    \n",
    "\n",
    "\n",
    "    elif interval == '3d':\n",
    "        df_resampled = df.resample('3D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "                \n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=2)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=2))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(0, closest_diff):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('3D', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "    elif interval == '3M':\n",
    "        df_resampled = df.resample('QS', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "        }).dropna()\n",
    "        reference_date = reference_date\n",
    "\n",
    "# Filtracja danych do zakresu +/- 2 dni od reference_date\n",
    "        closest_row = df_resampled[(df_resampled.index >= reference_date - pd.Timedelta(days=60)) & \n",
    "                        (df_resampled.index <= reference_date + pd.Timedelta(days=60))]\n",
    "\n",
    "        # Jeśli znaleziono dopasowanie, oblicz różnicę w dniach\n",
    "        if not closest_row.empty:\n",
    "            closest_match = closest_row.index[abs((closest_row.index - reference_date).days).argmin()]\n",
    "            closest_diff = abs((closest_match - reference_date).days)\n",
    "        if closest_diff>0:\n",
    "            df_new= df.copy()\n",
    "            for i in range(1, closest_diff+1):\n",
    "                new_index =  df_new.index[0]- pd.Timedelta(days=1)\n",
    "                new_entry = pd.DataFrame({\n",
    "                    'open': [first_entry.open],\n",
    "                    'high': [first_entry.open],\n",
    "                    'low': [first_entry.open],\n",
    "                    'close': [first_entry.open],\n",
    "                    'volume': [0]\n",
    "                }, index=[new_index])\n",
    "        \n",
    "                df_new = pd.concat([new_entry, df_new]).sort_index()\n",
    "            df_resampled = df_new.resample('Q', label='left', closed='left').agg({\n",
    "            'open': 'first',\n",
    "            'high': 'max',\n",
    "            'low': 'min',\n",
    "            'close': 'last',\n",
    "            'volume': 'sum'\n",
    "            }).dropna()\n",
    "            print(\"BBB\")\n",
    "            print(df_resampled)\n",
    "\n",
    "    \n",
    "    # Reset index to get timestamp as a column\n",
    "    df_resampled.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    return df_resampled\n",
    "\n",
    "# Load your data (Assuming CSV format, adjust if JSON)\n",
    "\n",
    "\n",
    "def load_data(ticker, interval, folder):\n",
    "    # Replace '/' with '.' in the ticker symbol\n",
    "    symbol = ticker.replace('/', '.')\n",
    "    \n",
    "    # Create the directory path\n",
    "    symbol_directory = os.path.join(folder, symbol)\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(symbol_directory):\n",
    "        os.makedirs(symbol_directory)\n",
    "    \n",
    "    # Create the file path\n",
    "    file_path = os.path.join(symbol_directory, interval + '.csv')\n",
    "    \n",
    "    # Load the data from the CSV file if it exists\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, parse_dates=['timestamp'])\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def resample_data_and_save(folder, symbol, interval, reference_data):\n",
    "    basic_data = load_data(symbol, '1d', folder)\n",
    "    resampled_data = resample_daily_to_weekly(basic_data, interval, reference_date=reference_data)\n",
    "\n",
    "    save_resampled_data(folder, resampled_data, symbol, interval)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_row_data_5m_1d(ticker):\n",
    "    basic_data=get_intraday_stock_data_batch(your_api_key, ticker, \"5m\", 1740787200, 10000, 500)\n",
    "    save_resampled_data(\"row_data\", basic_data, ticker, \"5m\")\n",
    "    resame_data_and_save(basic_data,'row_data', ticker, [ '15m', '30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n",
    "    \n",
    "def save_row_data_1m_1d(ticker):\n",
    "    basic_data=get_intraday_stock_data_batch(your_api_key, ticker, \"1m\", 1740787200, 10000, 500)\n",
    "    save_resampled_data(\"row_data\", basic_data, ticker, \"1m\")\n",
    "    resame_data_and_save(basic_data,'row_data', ticker, [ '5m', '15m', '30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n",
    "\n",
    "def save_row_data_15m_1d(ticker):\n",
    "    basic_data=get_intraday_stock_data_batch(your_api_key, ticker, \"15m\", 1740787200, 10000, 500)\n",
    "    save_resampled_data(\"row_data\", basic_data, ticker, \"5m\")\n",
    "    resame_data_and_save(basic_data,'row_data', ticker, ['30m', '1h', '2h', '4h', '6h', '12h' ,'1d'])\n",
    "#save_row_data_1m_1d(\"NVDA\", \"15m\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KONIEC\n"
     ]
    }
   ],
   "source": [
    "folder = 'row_data'\n",
    "tickers= ['USDJPY.FOREX','NDX.INDX', 'DJI.INDX', 'NATGAS.OANDA' , 'XAUUSD.FOREX', 'PLTR', 'PG', 'USDJPY.PEPPERSTONE' , 'GSPC.INDX', 'USDJPY.PEPPERSTONE','XAGUSD.OANDA', 'XAUUSD.OANDA', 'XPDUSD.OANDA' , 'COFFEE.PEPPERSTONE' , 'COCOA.PEPPERSTONE', 'EURJPY.OANDA', 'EURUSD.OANDA', 'USDPLN.FOREX' ]\n",
    "\n",
    "for ticker in tickers:\n",
    "    save_row_data_5m_1d(ticker )\n",
    "    print(ticker)\n",
    "    resample_data_and_save(folder, ticker, \"2d\", reference_data=pd.Timestamp(\"2025-01-31\"))\n",
    "    resample_data_and_save(folder, ticker, \"3d\", reference_data=pd.Timestamp(\"2025-01-30\"))\n",
    "    resample_data_and_save(folder, ticker, \"1w\", reference_data=pd.Timestamp(\"2024-12-30\"))\n",
    "    resample_data_and_save(folder, ticker, \"2w\", reference_data=pd.Timestamp(\"2024-12-30\"))\n",
    "    resample_data_and_save(folder, ticker, \"1M\", reference_data=pd.Timestamp(\"2024-12-01\"))\n",
    "    resample_data_and_save(folder, ticker, \"3M\", reference_data=pd.Timestamp(\"2024-10-01\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_daily_stock_data(api_key, ticker):\n",
    "    url = f\"https://api.profit.com/data-api/market-data/historical/daily/{ticker}\"\n",
    "    params = {\n",
    "        \"token\": api_key,\n",
    "        \"ticker\":ticker,\n",
    "        \"start_date\": \"1990-01-01\",\n",
    "        \"end_date\": \"2025-02-10\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        df = pd.DataFrame(response)\n",
    "        df['timestamp'] = pd.to_datetime(df['t'], unit='s')\n",
    "        df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 'v': 'volume'}, inplace=True)\n",
    "        df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        return None\n",
    "    \n",
    "def save_resampled_daily_data(folder, df, ticker, interval):\n",
    "    \n",
    "    symbol=ticker.replace('/', '.')\n",
    "    # Utwórz ścieżkę do pliku\n",
    "    symbol_directory=os.path.join(folder, 'daily', symbol)\n",
    "    if not os.path.exists(symbol_directory):\n",
    "    # Jeśli nie istnieje, utwórz go\n",
    "        os.makedirs(symbol_directory)\n",
    "    file_path = os.path.join(symbol_directory, interval+'.csv')\n",
    "\n",
    "    \n",
    "    df.to_csv(file_path, index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "ticker='USDJPY.FOREX'\n",
    "daily_data = get_daily_stock_data(your_api_key, ticker)\n",
    "\n",
    "if daily_data:\n",
    "    save_resampled_daily_data(\"row_data\", daily_data, ticker, \"1d\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data_and_save(folder, symbol, interval, reference_data):\n",
    "    basic_data = load_data(symbol, '1d', folder)\n",
    "    resampled_data = resample_daily_to_weekly(basic_data, interval, reference_date=reference_data)\n",
    "\n",
    "    save_resampled_data(folder, resampled_data, symbol, interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
